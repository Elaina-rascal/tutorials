# 算法组培训大纲
## 培训内容大纲

### 共9课，每课 1 小时左右，偏速成向而非精讲，需要自学

# Part 1 算法基础

### 第一课 环境配置
- linux 刷机到移动硬盘
- 什么是依赖,静态库与动态库
- linux包管理apt,ppa 与 ros包管理rosdep
- cmake 安装全局包
- 配置vscode 进行开发


### 任务: 在linux中安装Voxel-SLAM
- 禁止使用docker 
- 项目链接 https://github.com/hku-mars/Voxel-SLAM
> 验收时间:3天后
### 第二课 语言基础
- 面向对象的思想 **
- c++的函数模版
- c++的编译过程
- cmake的使用

### 第三课 ROS基础
- ros介绍
- 新建工作空间与添加功能包
- 话题的订阅发布模型 **
- launch,传参与yaml
- ros bag 介绍
### 任务: 用c++和python编写ROS2节点+launch
- 用面向对象编程
- C++编写发布者,在开启3s后发送**任意字符串**到一个话题
- Python编写订阅者,在收到**同名字符串**的时候在控制台打印**同名字符串**
- 两个节点用一个launch进行启动,并且将上文的任意字符串当成参数传入节点

> 验收时间:9/7 晚上12点截止,发送演示视频,包括launch启动和改参数之后launch启动
<!-- - 使用ros bag 与foxglove进行调试 -->
### 第四课 docker使用
- docker与image 的区别以及dockerhub是什么
- docker的常用语法 **
- docker run 与docker compose 启动容器
<!-- - 开发容器的使用 -->
- docker的常见问题


### 第五课 图像处理
- opencv 介绍
- hsv与rgb色彩空间
- aruco 码识别与pnp解算
- yolo识别物块

# Part 2 工程项目开发


### 第六课 工作流介绍
- konsole与开发容器使用
- ros2与ros1 之间的通信
- foxglove+数据包的使用
### 第七课 算法通识
- 设备驱动ros包
- imu, 里程计和对应ros消息
- 激光雷达线雷达,点云与laserscan
- 深度相机 
- 串口介绍与收发数据帧,udev设备管理

### 第八课 机器人定位
- tf树介绍
- slam介绍与其缺点
- slam 的数据源需求
- 数据融合 
### 第九课 团队协作与远程开发
- git的使用
- 代码规范与文档
- 三种远程开发方式
- 代码框架介绍

### 题目一 （讲完 Part 1 公布）
个人任务,限时9/10晚上12点

写一个ros2节点,在启动后3s播放fast lio数据包并开启slam

1. 所有的环境封装进一个docker
2. slam节点与ros2节点用一个launch启动
> 上传演示视频与代码源文件
### 题目二  （讲完 Part 2 公布）
自行分组 1~3 人

采用 ***压力考核*** 原则，限时一个月（9.15 - 9.29）

***仅提供***2025年视觉仓库

允许使用 ***网络工具***，允许使用 ***AI辅助***

通过自行建立库、工程、自行编写代码，给 **2025赛季R1** 的工控机代码，按顺序完成以下任务：



1. 在ros2驱动激光雷达和Imu获得原始数据
2. 用上面数据跑通voxelslam算法
3. 获得电控的码盘数据进行slam融合
4. 记录下传感器数据并可以通过播放复现
5. 部署导航加线雷达完成避障 (ros2 ros1 自选)

代码要求：
1. 安全可控
2. 结构清晰
3. 分文件管理合理